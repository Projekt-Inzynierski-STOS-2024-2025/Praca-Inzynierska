% LTex: language=pl
\section{Koncepcja wdrożenia jako klaster Kubernetes}
Aby efektywnie wykorzystać wcześniej wspomniane mechanizmy ograniczania wykorzystywanych zasobów sprzętowych, pierwsza koncepcja architektury wdrożenia systemu była oparta na orkiestratorze kontenerów Kubernetes, systemie pozwalającym na zautomatyzowane wdrażanie, skalowanie i~zarządzanie potencjalnie wysoką liczbą kontenerów\cite{k8sMain}.

\subsection{Orkiestratory kontenerów}
Wraz ze wzrostem popularności architektur aplikacji opartych na mikroserwisach, wzrosła również podaż na systemy pozwalające na zarządzanie, monitorowanie i~skalowanie instancji poszczególnych serwisów aplikacji wdrożonych na wielu maszynach fizycznych, szczególnie w~dużych systemach komercyjnych. Odpowiedzią rynku wypełniającą tę lukę są systemy orkiestracji kontenerów. Dwoma najpopularniejszymi orkiestratorami na rynku są Kubernetes i~Docker Swarm.

\subsubsection{Docker Swarm}
Docker Swarm to rozwiązanie wbudowane bezpośrednio w~silnik Dockera, pozwalające na stosunkowo proste wdrożenie złożonych aplikacji\cite{dockerSwarm}. Zawiera podstawowe funkcjonalności orkiestratora, takie jak wdrażanie aplikacji za pomocą plików konfiguracyjnych (korzysta ze standardu Docker Compose\cite{dockerCompose}), monitorowanie stanu serwisów oraz obsługę wdrożenia na kilku maszynach fizycznych. Niewątpliwą zaletą tego rozwiązania jest jego prostota i~stosunkowo niski próg wejścia dla użytkowników zaznajomionych z technologią Docker i~Docker Compose, co pozwala na uniknięcie kosztów związanych ze szkoleniem administratora systemu. Jednakże prostota ta wiąże się również z ograniczeniem możliwości konfiguracji takiego systemu, a~dość niska popularność Docker Swarm w~porównaniu do Kubernetes niesie za sobą koszty związane z samodzielną implementacją pewnych rozwiązań, których odpowiedniki w~technologii Kubernetes są dostępne za darmo i~utrzymywane przez społeczność.
\subsubsection{Kubernetes}
Kubernetes to rozwiązanie, z którego korzystają największe projekty komercyjne\cite{googleKubernetes}, początkowo rozwijane przez firmę Google. Sam system Kubernetes dostępny jest, podobnie jak system operacyjny Linux, w~postaci różnych dystrybucji. Spółki oferujące usługi chmurowe dla klientów, takie jak Amazon i~Google, często decydują się na rozwój własnych dystrybucji Kubernetesa, lecz istnieją również dystrybucje przeznaczone dla mniejszych projektów, takie jak MicroKubernetes\cite{microk8s}, który został wykorzystany podczas prototypowania rozwiązania wdrożenia systemu STOS-new. Kubernetes posiada bogaty ekosystem i~wbudowane rozwiązania, pozwalające na znaczące uproszczenie konfiguracji wirtualnej sieci, w~której znajduje się wdrażany system. Rozwiązanie to, w~przeciwieństwie do Docker Swarm, jest niezależne od zastosowanej technologii konteneryzacji, pozwalając na używanie więcej niż jednej technologii w~ramach jednego klastra. Dodatkowo Kubernetes wspiera menadżera pakietów/zasobów w~postaci programu Helm\cite{k8sHelm}, dzięki czemu dostępnych jest wiele darmowych rozwiązań utrzymywanych przez społeczność, pozwalających między innymi na automatyczne gromadzenie logów i~monitorowanie poszczególnych serwisów wdrożonych w~systemie. Podobnie jak w~przypadku Docker Swarm, stopień skomplikowania Kubernetesa stanowi jego największą zaletę i~wadę. Przez wysoki próg wejścia, administracja systemem, a~w~szczególności jej nauka, stanowi czasochłonny proces. Podobnie jest w~przypadku utrzymania, dla osób niezaznajomionych z Kubernetesem i~jego poszczególnymi elementami, diagnostyka potencjalnych problemów i~ich naprawa staje się nieporównywalnie trudniejszym zadaniem niż w~przypadku Docker Swarm. Jednakże, rozwiązanie wdrożone na bazie klastra Kubernetes oferuje o~wiele więcej możliwości potencjalnego rozwoju systemu, zarówno pod względem bardziej rozbudowanej architektury jak i~wdrażania dodatkowych rozwiązań monitorowania.

\subsection{Wybór orkiestratora}
Mając na uwadze wady i~zalety rozwiązań opartych o~MicroKubernetes i~Docker Swarm, podjęto decyzję o~początkowym rozwoju rozwiązań opartych o~obie z tych technologii. Faktycznie, wdrożenie samej aplikacji za pomocą Docker Swarm zajęło zauważalnie mniej czasu niż w~przypadku MicroKubernetesa (osoba wdrażająca nie miała wcześniejszego doświadczenia z żadnym z tych systemów). Przy próbie wdrożenia rozwiązania pozwalającego na monitorowanie logów systemu, prawidłowość ta prezentowała się zgoła odwrotnie -- dzięki menadżerowi pakietów Helm, wdrożenie tzw. „stacka ELK” (czyli aplikacji Elasticsearch, Logstash i~Kibana) na klastrze MicroKubernetes odbyło się nieporównywalnie szybciej niż w~przypadku Docker Swarm, który wymagał ręcznej konfiguracji poszczególnych kontenerów odpowiedzialnych za każdy z serwisów wchodzących w~skład rozwiązania zbierającego logi z systemu. Na podstawie doświadczeń związanych z utrudnionym wdrożeniem zewnętrznych systemów na klastrze Docker Swarm i~możliwych przyszłych komplikacjach przy konieczności dodawania kolejnych serwisów do klastra, podjęto decyzję o~kontynuowaniu prac z MicroKubernetesem.

\subsection{Prototyp wdrożenia i~jego zalety}
Z perspektywy administratorów systemu STOS-new i~pracowników katedry, którzy w~przyszłości będą utrzymywać i~rozwijać system STOS-new, główną zaletą podejścia opartego o~technologię orkiestracji kontenerów, w~słowach inżynierów firmy Google\cite{googleKubernetes}, jest przeniesienie wielu odpowiedzialności ze środowiska, w~którym działa aplikacja, na samą aplikację. Pozwala to na uniezależnienie obecnych i~przyszłych komponentów systemu STOS-new od środowiska, w~którym zostały wdrożone, co znacząco ułatwia prowadzącym lub studentom rozwijającym i~utrzymującym system STOS-new na dodawanie, lub modyfikowanie jego funkcjonalności. Ponadto Kubernetes zawiera wbudowane funkcjonalności monitorowania zużycia zasobów systemowych i~umożliwia konfigurację automatycznego ponownego uruchamiania aplikacji po wystąpieniu błędu\cite{k8sPod}.

\begin{figure}[!h]
	\begin{center}
		\resizebox{0.7\textwidth}{!} {
			\includegraphics{img/4/k8s.png}
		}
		\caption[Diagram prototypu klastra Kubernetes]{Diagram przedstawiający elementy prototypu klastra Kubernetes wdrożonego dla systemu STOS-new. Źródło własne.}
		\label{diagramk8s}
	\end{center}
\end{figure}

W ramach projektu inżynierskiego powstał prototyp takiego klastra, zawierający symulowaną architekturę systemu STOS-new (\ref{diagramk8s}). Umożliwiał on dynamiczne skalowanie ilości instancji serwisu kompilującego \textit{(worker)}, odpowiedzialnego za ewaluację zadań przesyłanych przez studentów, jak i~monitorowanie stanu wszystkich działających w~ramach systemu usług.

Oprócz samych komponentów systemowych STOS-new zaprojektowany klaster oferował również szereg usług dodatkowych. Jedną z nich jest wbudowany serwer DNS, który znacząco ułatwia konfigurację komunikacji pomiędzy usługami systemu\cite{k8sDns}. Drugim najważniejszym komponentem był „service” w~kontekście Kubernetesa, pełniący funkcję load-balancera dla poszczególnych serwisów kompilujących \textit{(worker)}. Tym sposobem, zagwarantowano równomierne obciążenie każdej instancji serwisu, bez względu na ilość działających kontenerów\cite{k8sService}. Ostatnim z elementów klastra była usługa Ingress, pozwalająca na jednoznaczne zdefiniowane punktu dostępu do serwisów klastra ze środowiska zewnętrznego, którym w~tym prototypie był serwis zarządzający \textit{(manager)}\cite{k8sIngress}.

\subsection{Koncepcja wdrożenia a~dynamika wymagań}
Jednakże, w~trakcie prac i~w~kontekście dynamicznie zmieniających się wymagań, wdrożenie systemu STOS-new jako klaster oparty na orkiestratorze kontenerów okazało się przedsięwzięciem bardziej skomplikowanym, niż mogłoby się to wydawać na początku prac. Wymaganiem była możliwość kontrolowania kontenerów Docker z poziomu samej aplikacji, będącej częścią systemu STOS-new. Łączyło się ono z większym stopniem złożoności rozwiązania spowodowanej wprowadzeniem dodatkowych komponentów lub zastosowaniem zaawansowanych wzorców projektowych przeznaczonych dla skonteneryzowanych aplikacji rozproszonych, takich jak „wózek boczny” \textit{(sidecar pattern)}\cite{k8sPatterns}. Projekt rozwiązania opierającego się na klastrze Kubernetes i~korzystający z dodatkowych komponentów systemowych przedstawiono na rysunku \ref{diagramk8sFinal}.

\begin{figure}[!h]
	\begin{center}
		\resizebox{0.7\textwidth}{!} {
			\includegraphics{img/4/k8sFinal.png}
		}
		\caption[Diagram prototypu klastra Kubernetes po zmianie architektury]{Diagram przedstawiający ogólną architekturę systemu wdrożonego na klaster Kubernetes po zmianie wymagań dotyczących konteneryzacji serwisu kompilującego \textit{(worker)}. Źródło własne.}
		\label{diagramk8sFinal}
	\end{center}
\end{figure}

Zgodnie z wymaganiami, których źródłem są istniejące komponenty systemu STOS, komunikacja między kontenerem kompilującym i~serwisem zarządzającym \textit{(manager)} musi być zrealizowana za pomocą współdzielonych katalogów. Taki mechanizm oferowany jest zarówno w~postaci wolumenów w~Dockerze\cite{dockerVolume}, jak i~StatefulSet w~Kubernetes\cite{k8sStateful}. Za zlecanie ewaluacji zadania i~dynamiczne uruchamianie serwisu kompilującego \textit{(worker)}, w~tym modelu systemu odpowiedzialny jest dedykowany serwis uruchomiony poza klastrem, posiadający pełny dostęp do mechanizmów zarządzania tym klastrem.

Dodanie serwisu, którego awaria wiąże się z awarią całego systemu w~postaci zewnętrznego serwisu nadzorującego stan klastra i~cykl życia kontenerów to tylko część wad tego rozwiązania. Przy zastosowaniu kontenerów, które muszą utrzymywać swój stan, czyli skorzystaniu z technologii StatefulSet, dodatkowym czynnikiem przyczyniającym się do skomplikowania aplikacji jest zarządzanie współdzielonymi wolumenami, z których korzysta serwis zarządzający \textit{(manager)} w~celu komunikacji z instancjami serwisu kompilującego \textit{(worker)}. Dodatkowo niemożliwe staje się zastosowanie wbudowanego w~klaster Kubernetes serwisu odgrywającego rolę serwisu odpowiadającego za sprawiedliwy rozkład żądań przychodzących do poszczególnych instancji serwisów \textit{(load-balancer)}, co wiąże się z koniecznością ręcznej implementacji tej funkcjonalności.

Z racji rosnącego stopnia skomplikowania wdrożenia systemu STOS-new za pomocą klastra Kubernetes, podjęta została decyzja o~zaprojektowaniu rozwiązania nieopierającego się na technologii orkiestracji kontenerów.
